---

title: "Introduction"
teaching: 15
exercises: 0
questions:
- "What is the purpose of having a HiMAT data infrastructure?"
- "Who are the clients and what are some typical use cases?"
- "What methods are in place to ensure my data are safe?"
- "What kinds of support and services can I expect from each of the different data coordinators?"
- "How can I work to help this progress as smoothly as possible?"
objectives:
- "review different categories of data (raster, vector, time series)"
- "learn which data centers will be responsible for handling each kind of data"
- "learn best practices to ensure data transfer and access occurs smoothly across the team"
key points:
- "Where you go to store and find data during HiMAT project depends on the data type, size and usage constraints"
- "Several methods/data centers are provided and users can choose which approach works best"
- "co-location of processing/analysis with data storage is encouraged, to minimize transfer of large files" 
---

## Introduction 

The purpose of this page is to describe a cloud-aligned [research project](http://himat.org) with the purposes of advancing scientific understanding of the hydrology of the mountain ranges of High Mountain Asia. 

## HiMAT data infrastructure

A core feature of the HiMAT project is the construction and utilization of data sharing tools to foster efficient collaboration, reproducible research and enhanced stakeholder engagement. Our cloud-based data infrastructure aims to addresses several of the challenges that often limit effective collaboration in such large projects:

* cross-team collaboration necessitates the sharing of preliminary data products which are not yet fully validated and may not be ready to share with the public. Existing data infrastructures primarily store completed datasets on public-facing servers. So there is a considerable gap in our provisioning of privately accessible, cloud-based computational tools for this kind of research.
* datasets to be generated by HiMAT are particularly voluminous, for example high resolution satellite imagery. Many existing data centers are not set up to handle data of this size, and even if they are, it is unreasonable to be downloading datasets this large to local machines. Therefore we need methods to co-locate our processing/analysis with the location at which the data are stored.
* the development collaborative tools calls for some degree of customization in our computational infrastructure if we are to integrate our products and provide decision support to the region. Therefore investigators need to have full access to both front and backend computational components, without the need to submit requests to third party agencies. 

To address these challenges we are designing a multi-tiered approach to data handling, one that considers the type of data (raster, vector, time series) as well as its maturity/readiness for distribution:

<br>
<img src="../fig/himatDataDiagram.png" width = "600" border = "10">
<br>

Next we describe the different data storage and computational resources being provisioned for this effort.

### NASA ADAPT

The NASA Center for Climate Simulation (NCCS) provides NASA-funded researchers with high performance computing resources. Within NCCS exists the Advanced Data Analytics Platform ([ADAPT](https://www.nccs.nasa.gov/services/adapt)), which is an on-site private cloud designed for large-scale data analytics.

Within HiMAT we have provided researchers with the opportunity to access ADAPT resources. Team members must pass through a screening and security [process](https://www.nccs.nasa.gov/services/adapt/user_access/how_do_i_get_access) and receive approval from the team lead and NASA administrators. 

Within the ADAPT infrastructure we have provisioned approximately 15 Virtual Machines (VMs). Once users have been approved for access they can connect to these resources [via SSH](https://www.nccs.nasa.gov/services/adapt/how_to_use_adapt/logging_into_adapt) through either Linux or Windows operating systems.

ADAPT provides HiMAT with direct access to the full Landsat, MODIS and MERRA [data sets](https://www.nccs.nasa.gov/services/adapt/data). As team members generate new products, we will be hosting these in a file structure similar to that used for the existing NASA remote sensing and climate reanalysis datasets. Each user also has access to a 15 GB home directory and a 5 TB nobackup/scratch directory for large temporary files.

 





